Table of contents

* [Introduction](#Introduction)
* [Hadoop Cluster](#Hadoop cluster)
* [Hive Project](#Hive Projecr)
* [Improvements](#Improvements)

# Introduction

In this project,the Jarvis Data Analytics Team wants to move from SAP and R to Hadoop Ecosystem to process the big data using Apache  Hadoop.
We were tasked with analyzing and processing the World Development Indicators (WDI) dataset, which contains approximately 22 million data points.
Used Apache Hadoop, HDFS, YARN, Hive, Zeppelin to process World Development Indicators (WDI) and generate meaningful insights.
- Provisioned Hadoop Cluster on GCP (Google Cloud Platform).
- Solved business problems using Apache Hive and Zeppelin Notebook.

# Hadoop Cluster

